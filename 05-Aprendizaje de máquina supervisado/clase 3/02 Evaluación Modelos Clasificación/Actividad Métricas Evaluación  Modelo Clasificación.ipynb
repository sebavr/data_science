{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b1b057",
   "metadata": {},
   "source": [
    "### Actividad Métricas Evaluación Modelo Clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5e917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2defd42c",
   "metadata": {},
   "source": [
    "### Datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adfcc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_scores.csv')\n",
    "df2 = pd.read_csv('resultado_metricas.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad07a30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours  Scores\n",
       "0    2.5      21\n",
       "1    5.1      47\n",
       "2    3.2      27\n",
       "3    8.5      75\n",
       "4    3.5      30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d475680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aprobado_Desaprobado</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Aprobado_Desaprobado  pred\n",
       "0                     1     1\n",
       "1                     1     1\n",
       "2                     1     1\n",
       "3                     0     0\n",
       "4                     1     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48c0794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=df2[['Aprobado_Desaprobado']].squeeze()\n",
    "y_pred=df2[['pred']].squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebc1ae",
   "metadata": {},
   "source": [
    "### Matriz de Confusión\n",
    "\n",
    "Primero vamos a crear una matriz de confusión con la función crosstab (crea una tabla pivoteada con la frecuencia de los elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d5e6465",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50cf6029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1  All\n",
       "True                  \n",
       "0          11   0   11\n",
       "1           0  14   14\n",
       "All        11  14   25"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af80c3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:14, TN:11, FP:0, FN:0, TOT:25\n"
     ]
    }
   ],
   "source": [
    "# Complete los valores de los arreglos\n",
    "\n",
    "# True Negative\n",
    "TN = pdf[0][0]\n",
    "\n",
    "# True Positive\n",
    "TP = pdf[1][1]\n",
    "\n",
    "# False Negative\n",
    "FN = pdf[1][0]\n",
    "\n",
    "# False Positive\n",
    "FP = pdf[0][1]\n",
    "\n",
    "# Total\n",
    "TOT = TN + TP + FN + FP\n",
    "\n",
    "print(\"TP:{}, TN:{}, FP:{}, FN:{}, TOT:{}\".format(TP,TN,FP,FN,TOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cf2f3",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1322798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurracy is : 1.0\n",
      "Precision is : 1.0\n",
      "Recall is : 1.0\n",
      "Specifity is : 1.0\n",
      "F1 Score is : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy (Precisión)\n",
    "acc =(TP+TN)/TOT\n",
    "print(\"Accurracy is :\", round(acc,2))\n",
    "\n",
    "# Precision (Exactitud)\n",
    "prec =TP/(FP+TP)\n",
    "print(\"Precision is :\", round(prec,2))\n",
    "\n",
    "# Recall (Sensibilidad)\n",
    "rec =TP/(TP+FN)\n",
    "print(\"Recall is :\", round(rec,2))\n",
    "\n",
    "# Specifity (Especificidad)\n",
    "spe =TN/(TN+FP)\n",
    "print(\"Specifity is :\", round(spe,2))\n",
    "\n",
    "# F1-Score = 2 * (precision x recall / (precision + recall))\n",
    "# F1 Score takes into account precision and the recall. It is created by finding the the harmonic mean of precision and recall.\n",
    "f1 =2*(prec*rec)/(prec+rec)\n",
    "print(\"F1 Score is :\", round(f1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b65a4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3af3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report which includes Precision, Recall and F1-Score.\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ac39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
